{
  "provider": "ollama",
  "model": "llama3:latest",
  "temperature": 0.7,
  "maxTokens": 2048
}
