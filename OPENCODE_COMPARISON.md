# OpenCode vs SuperCoin: í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ë™ì‘ íë¦„ ë¹„êµ ë¶„ì„

> **ëª©ì **: OpenCodeì˜ ì•„í‚¤í…ì²˜ë¥¼ ë¶„ì„í•˜ê³ , SuperCoinì„ OpenCode êµ¬ì¡°ë¡œ ê°œì„ í•˜ë˜ Centë¥¼ ì‚¬ìš©í•˜ê³  localhostë¥¼ í†µí•´ ë™ì‘í•˜ë„ë¡ ì„¤ê³„

---

## ğŸ“‹ ëª©ì°¨

1. [OpenCode í”„ë¡œì íŠ¸ êµ¬ì¡°](#1-opencode-í”„ë¡œì íŠ¸-êµ¬ì¡°)
2. [SuperCoin í˜„ì¬ êµ¬ì¡°](#2-supercoin-í˜„ì¬-êµ¬ì¡°)
3. [í•µì‹¬ ì•„í‚¤í…ì²˜ ì°¨ì´ì ](#3-í•µì‹¬-ì•„í‚¤í…ì²˜-ì°¨ì´ì )
4. [ë™ì‘ íë¦„ ë¹„êµ](#4-ë™ì‘-íë¦„-ë¹„êµ)
5. [ê°œì„  ë°©í–¥: SuperCoin â†’ OpenCode êµ¬ì¡°](#5-ê°œì„ -ë°©í–¥-supercoin--opencode-êµ¬ì¡°)
6. [Localhost ëª¨ë¸ í†µí•© ê°€ì´ë“œ](#6-localhost-ëª¨ë¸-í†µí•©-ê°€ì´ë“œ)
7. [êµ¬í˜„ ë¡œë“œë§µ](#7-êµ¬í˜„-ë¡œë“œë§µ)

---

## 1. OpenCode í”„ë¡œì íŠ¸ êµ¬ì¡°

### 1.1 ì „ì²´ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
opencode/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ opencode/              # ë©”ì¸ CLI íŒ¨í‚¤ì§€
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ agent/         # Sisyphus ë° ì„œë¸Œ ì—ì´ì „íŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ provider/      # AI ëª¨ë¸ í”„ë¡œë°”ì´ë” ì¶”ìƒí™”
â”‚   â”‚   â”‚   â”œâ”€â”€ session/       # ì„¸ì…˜ ê´€ë¦¬ ë° LLM ìŠ¤íŠ¸ë¦¬ë°
â”‚   â”‚   â”‚   â”œâ”€â”€ tool/          # ë„êµ¬ ì‹œìŠ¤í…œ (bash, file, search ë“±)
â”‚   â”‚   â”‚   â”œâ”€â”€ config/        # ì„¤ì • ë¡œë” (global, project, remote)
â”‚   â”‚   â”‚   â”œâ”€â”€ auth/          # ì¸ì¦ ê´€ë¦¬ (OAuth, API Key)
â”‚   â”‚   â”‚   â””â”€â”€ cli/           # CLI ì§„ì…ì 
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”œâ”€â”€ web/                   # ì›¹ ëŒ€ì‹œë³´ë“œ (Next.js)
â”‚   â””â”€â”€ models/                # Models.dev í†µí•©
â””â”€â”€ docs/
```

### 1.2 í•µì‹¬ ì»´í¬ë„ŒíŠ¸

#### **A. Cent Agent (Main Orchestrator)**

```typescript
// packages/opencode/src/agent/coin.ts
export class CoinAgent {
  async execute(userInput: string, context: SessionContext) {
    // 1. ì‚¬ìš©ì ì…ë ¥ ë¶„ì„
    const intent = await this.analyzeIntent(userInput)
    
    // 2. ì ì ˆí•œ ì„œë¸Œ ì—ì´ì „íŠ¸ ì„ íƒ ë° ìœ„ì„
    if (intent.type === 'explore') {
      return await this.delegateToExplore(userInput, context)
    } else if (intent.type === 'implement') {
      return await this.delegateToExecutor(userInput, context)
    }
    
    // 3. ê²°ê³¼ ì·¨í•© ë° ì‚¬ìš©ìì—ê²Œ ì‘ë‹µ
    return this.synthesizeResponse(results)
  }
  
  private async delegateToExplore(...) {
    // ì„œë¸Œ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—… ìœ„ì„
    const exploreAgent = this.registry.get('explore')
    return await exploreAgent.run(...)
  }
}
```

**ì£¼ìš” ì—­í• :**
- ì‚¬ìš©ì ì˜ë„ íŒŒì•… (intent classification)
- ì„œë¸Œ ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (delegation)
- ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ (session state)
- ê²°ê³¼ í†µí•© (result synthesis)

#### **B. Provider Abstraction (AI ëª¨ë¸ í†µí•©)**

```typescript
// packages/opencode/src/provider/provider.ts
export namespace Provider {
  // í”„ë¡œë°”ì´ë”ë³„ ì¶”ìƒí™”
  const BUNDLED_PROVIDERS: Record<string, (options: any) => SDK> = {
    "@ai-sdk/anthropic": createAnthropic,
    "@ai-sdk/openai": createOpenAI,
    "@ai-sdk/google": createGoogleGenerativeAI,
    "@ai-sdk/openai-compatible": createOpenAICompatible, // Ollama, LM Studio ë“±
  }
  
  // ëª¨ë¸ ë¡œë“œ
  async function getLanguage(model: Model): Promise<LanguageModelV2> {
    const provider = BUNDLED_PROVIDERS[model.api.npm]
    const sdk = provider({
      apiKey: await getApiKey(model.providerID),
      baseURL: model.api.url
    })
    
    return sdk.languageModel(model.id)
  }
}
```

**í•µì‹¬ ê¸°ëŠ¥:**
- 75+ í”„ë¡œë°”ì´ë” ì§€ì› (AI SDK ê¸°ë°˜)
- OpenAI-compatible API ì§€ì› (Ollama, LM Studio, llama.cpp)
- ëŸ°íƒ€ì„ í”„ë¡œë°”ì´ë” ìŠ¤ìœ„ì¹­
- ìë™ í† í° ê´€ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë°

#### **C. Session Management**

```typescript
// packages/opencode/src/session/session.ts
export class Session {
  id: string
  messages: Message[]
  tools: Tool[]
  context: {
    workdir: string
    model: string
    temperature: number
  }
  
  async stream(input: string) {
    const result = await streamText({
      model: this.getModel(),
      messages: [...this.messages, { role: 'user', content: input }],
      tools: this.tools,
      onFinish: (completion) => {
        this.messages.push({ role: 'assistant', content: completion.text })
      }
    })
    
    return result
  }
}
```

**ì„¸ì…˜ ë¼ì´í”„ì‚¬ì´í´:**
1. ì„¸ì…˜ ìƒì„± (`Session.create(workdir, model)`)
2. ë©”ì‹œì§€ ëˆ„ì  (conversation history)
3. ë„êµ¬ í˜¸ì¶œ ì¶”ì  (tool call history)
4. ì„¸ì…˜ ì €ì¥/ë³µì› (persistence)

#### **D. Tool System**

```typescript
// packages/opencode/src/tool/registry.ts
export class ToolRegistry {
  private tools: Map<string, Tool> = new Map()
  
  register(name: string, tool: Tool) {
    this.tools.set(name, tool)
  }
  
  async execute(name: string, args: any, context: ToolContext) {
    const tool = this.tools.get(name)
    return await tool.execute(args, context)
  }
}

// ë„êµ¬ ì˜ˆì‹œ
export const bashTool: Tool = {
  name: 'bash',
  description: 'Execute bash commands',
  parameters: z.object({
    command: z.string(),
    workdir: z.string().optional()
  }),
  execute: async (args, context) => {
    const result = await execCommand(args.command, args.workdir)
    return { stdout: result.stdout, stderr: result.stderr }
  }
}
```

---

## 2. SuperCoin í˜„ì¬ êµ¬ì¡°

### 2.1 ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
supercoin/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/                   # CLI ì»¤ë§¨ë“œ
â”‚   â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.ts       # ì¸ì¦ ê´€ë¦¬
â”‚   â”‚   â”‚   â”œâ”€â”€ models.ts     # ëª¨ë¸ ì„ íƒ
â”‚   â”‚   â”‚   â”œâ”€â”€ config.ts     # ì„¤ì •
â”‚   â”‚   â”‚   â””â”€â”€ server.ts     # ì„œë²„ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ auth/             # ì¸ì¦ ì„œë¹„ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ hub.ts        # AuthHub (ì¤‘ì•™ ê´€ë¦¬)
â”‚   â”‚   â”‚   â”œâ”€â”€ claude.ts     # Claude í”„ë¡œë°”ì´ë”
â”‚   â”‚   â”‚   â”œâ”€â”€ codex.ts      # Codex í”„ë¡œë°”ì´ë”
â”‚   â”‚   â”‚   â””â”€â”€ gemini.ts     # Gemini í”„ë¡œë°”ì´ë”
â”‚   â”‚   â”œâ”€â”€ models/           # ëª¨ë¸ ë¼ìš°í„°
â”‚   â”‚   â”‚   â”œâ”€â”€ router.ts     # ModelRouter
â”‚   â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚   â”‚       â”œâ”€â”€ anthropic.ts
â”‚   â”‚   â”‚       â”œâ”€â”€ openai.ts
â”‚   â”‚   â”‚       â””â”€â”€ google.ts
â”‚   â”‚   â”œâ”€â”€ agents/           # ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
â”‚   â”‚   â”‚   â”œâ”€â”€ coin.ts       # Coin ì—ì´ì „íŠ¸ (ë©”ì¸)
â”‚   â”‚   â”‚   â”œâ”€â”€ explorer.ts   # íƒìƒ‰ ì—ì´ì „íŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ analyst.ts    # ë¶„ì„ ì—ì´ì „íŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ executor.ts   # ì‹¤í–‰ ì—ì´ì „íŠ¸
â”‚   â”‚   â”‚   â””â”€â”€ registry.ts   # ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”‚   â”‚   â””â”€â”€ background/
â”‚   â”‚       â””â”€â”€ concurrency-manager.ts
â”‚   â”œâ”€â”€ core/                 # í•µì‹¬ ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ session.ts        # ì„¸ì…˜ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ tools/            # ë„êµ¬ ì‹œìŠ¤í…œ
â”‚   â”‚   â”‚   â”œâ”€â”€ bash.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ file.ts
â”‚   â”‚   â”‚   â””â”€â”€ search.ts
â”‚   â”‚   â””â”€â”€ hooks/            # í›… ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ server/               # Hono ì„œë²„
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ auth-callback.ts
â”‚   â”‚   â””â”€â”€ store/
â”‚   â”‚       â”œâ”€â”€ token-store.ts
â”‚   â”‚       â””â”€â”€ oauth-state-store.ts
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ schema.ts         # Zod ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â””â”€â”€ loader.ts         # ì„¤ì • ë¡œë”
â”‚   â””â”€â”€ supercoin.ts          # ë©”ì¸ í´ë˜ìŠ¤
â”œâ”€â”€ tests/
â””â”€â”€ package.json
```

### 2.2 í•µì‹¬ í´ë˜ìŠ¤: SuperCoin

```typescript
// src/supercoin.ts
export class SuperCoin {
  private config: SuperCoinConfig
  private _auth: AuthHub
  private _models: ModelRouter
  
  async chat(message: string) {
    const response = await this.models.route({
      messages: [{ role: 'user', content: message }]
    })
    return response.content
  }
  
  async runAgent(agentName: string, prompt: string) {
    const agent = this.getAgents().get(agentName)
    return await agent.execute(prompt, { sessionId, workdir })
  }
}
```

### 2.3 í˜„ì¬ ëª¨ë¸ í†µí•© ë°©ì‹

```typescript
// src/services/models/router.ts
export class ModelRouter {
  async route(request: ChatRequest): Promise<ChatResponse> {
    const provider = this.getProvider(this.currentModel.provider)
    
    // ê° í”„ë¡œë°”ì´ë”ë³„ë¡œ ì§ì ‘ API í˜¸ì¶œ
    if (provider.name === 'anthropic') {
      return await this.callAnthropic(request)
    } else if (provider.name === 'openai') {
      return await this.callOpenAI(request)
    }
  }
  
  private async callAnthropic(request: ChatRequest) {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'x-api-key': await this.auth.getToken('claude'),
        'anthropic-version': '2023-06-01'
      },
      body: JSON.stringify(...)
    })
    
    return await response.json()
  }
}
```

**ë¬¸ì œì :**
- ê° í”„ë¡œë°”ì´ë”ë§ˆë‹¤ ê°œë³„ êµ¬í˜„ í•„ìš” (ì¤‘ë³µ ì½”ë“œ)
- ìŠ¤íŠ¸ë¦¬ë° ì§€ì› ë¶ˆì¼ì¹˜
- ë„êµ¬ í˜¸ì¶œ í†µí•© ë¶€ì¡±
- localhost ëª¨ë¸ ì§€ì› ì–´ë ¤ì›€

---

## 3. í•µì‹¬ ì•„í‚¤í…ì²˜ ì°¨ì´ì 

### 3.1 ë¹„êµí‘œ

| êµ¬ë¶„ | OpenCode | SuperCoin | ì°¨ì´ì  |
|------|----------|-----------|--------|
 | **ë©”ì¸ ì—ì´ì „íŠ¸** | Sisyphus | Cent | ì´ë¦„ë§Œ ë‹¤ë¦„, ì—­í•  ìœ ì‚¬ |
| **ëª¨ë¸ í†µí•©** | AI SDK + Provider ì¶”ìƒí™” | ì§ì ‘ API í˜¸ì¶œ | OpenCodeê°€ í›¨ì”¬ í™•ì¥ì„± ë†’ìŒ |
| **í”„ë¡œë°”ì´ë” ìˆ˜** | 75+ (Ollama, LM Studio í¬í•¨) | 3ê°œ (Claude, Codex, Gemini) | OpenCodeê°€ ì••ë„ì  |
| **localhost ì§€ì›** | âœ… OpenAI-compatible API | âŒ ì§€ì› ì•ˆ í•¨ | í•µì‹¬ ì°¨ì´ |
| **ìŠ¤íŠ¸ë¦¬ë°** | AI SDK í†µí•© | ë¶€ë¶„ ì§€ì› | OpenCodeê°€ ì•ˆì •ì  |
| **ë„êµ¬ ì‹œìŠ¤í…œ** | í†µí•© Tool Registry | ê°œë³„ êµ¬í˜„ | ìœ ì‚¬í•˜ì§€ë§Œ OpenCodeê°€ ì²´ê³„ì  |
| **ì„¤ì • ì‹œìŠ¤í…œ** | Remote + Global + Project | Global only | OpenCodeê°€ ìœ ì—°í•¨ |
| **ì¸ì¦** | OAuth + API Key | OAuth + API Key | ìœ ì‚¬ (SuperCoinì´ ìµœê·¼ ê°œì„ ë¨) |

### 3.2 OpenCodeì˜ ê°•ì 

1. **Provider ì¶”ìƒí™”**: AI SDK ê¸°ë°˜ìœ¼ë¡œ 75+ í”„ë¡œë°”ì´ë” ìë™ ì§€ì›
2. **localhost ëª¨ë¸**: Ollama, LM Studio, llama.cpp ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
3. **ìŠ¤íŠ¸ë¦¬ë° ì¼ê´€ì„±**: ëª¨ë“  í”„ë¡œë°”ì´ë”ì—ì„œ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
4. **ì„¤ì • ê³„ì¸µ**: Remote â†’ Global â†’ Project â†’ Environment
5. **Models.dev í†µí•©**: ìµœì‹  ëª¨ë¸ ë©”íƒ€ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸

### 3.3 SuperCoinì˜ ê°•ì 

1. **ìµœì‹  OAuth êµ¬í˜„**: PKCE + CSRF ë³´í˜¸ (RFC 9700 ì¤€ìˆ˜)
2. **Multi-account ì§€ì›**: í”„ë¡œë°”ì´ë”ë‹¹ ìµœëŒ€ 10ê°œ ê³„ì •
3. **TypeScript íƒ€ì… ì•ˆì „ì„±**: ê°•ë ¥í•œ Zod ìŠ¤í‚¤ë§ˆ
4. **ê²½ëŸ‰**: ì˜ì¡´ì„± ìµœì†Œí™” (Bun ê¸°ë°˜)

---

## 4. ë™ì‘ íë¦„ ë¹„êµ

### 4.1 OpenCode: ì‚¬ìš©ì ì…ë ¥ â†’ ì‘ë‹µ

```
[ì‚¬ìš©ì]
  â†“ ì…ë ¥: "Refactor this function"
  
[CLI ì§„ì…ì ]
  â†“ packages/opencode/src/cli/index.ts
  
[Sisyphus Agent]
  â†“ ì˜ë„ ë¶„ì„: "code refactoring" â†’ IMPLEMENT ë¶„ë¥˜
  â†“ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ: í˜„ì¬ íŒŒì¼, git status, í”„ë¡œì íŠ¸ êµ¬ì¡°
  
[Provider.getLanguage()]
  â†“ ëª¨ë¸ ì„ íƒ: config.model â†’ "opencode/gpt-5.1-codex"
  â†“ SDK ë¡œë“œ: @ai-sdk/openai
  â†“ ì¸ì¦: API í‚¤ ìë™ ë¡œë“œ
  
[Session.stream()]
  â†“ System prompt: "You are Sisyphus, an AI coding agent..."
  â†“ ë©”ì‹œì§€ êµ¬ì„±: [system, ...history, user]
  â†“ ë„êµ¬ ë“±ë¡: { bash, read, write, search, ... }
  â†“ streamText() í˜¸ì¶œ
  
[AI SDK Streaming]
  â†“ ì‹¤ì‹œê°„ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
  â†“ ë„êµ¬ í˜¸ì¶œ ê°ì§€ â†’ Tool.execute()
  â†“ ê²°ê³¼ ë°˜í™˜
  
[Sisyphus]
  â†“ ê²°ê³¼ ê²€ì¦
  â†“ í›„ì† ì‘ì—… í•„ìš” ì‹œ ì„œë¸Œ ì—ì´ì „íŠ¸ í˜¸ì¶œ
  
[ì‚¬ìš©ì]
  â† ì‘ë‹µ ì¶œë ¥
```

### 4.2 SuperCoin: ì‚¬ìš©ì ì…ë ¥ â†’ ì‘ë‹µ

```
[ì‚¬ìš©ì]
  â†“ ì…ë ¥: "Refactor this function"
  
[CLI ì§„ì…ì ]
  â†“ src/cli/index.ts
  
[SuperCoin.runAgent('coin', prompt)]
  â†“ src/services/agents/coin.ts
  
[Coin Agent]
  â†“ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
  
[ModelRouter.route()]
  â†“ src/services/models/router.ts
  â†“ í˜„ì¬ ëª¨ë¸ í™•ì¸: "anthropic/claude-sonnet-4"
  
[AuthHub.getToken('claude')]
  â†“ src/services/auth/hub.ts â†’ claude.ts
  â†“ TokenStoreì—ì„œ API í‚¤ ë¡œë“œ
  
[AnthropicProvider.callAPI()]
  â†“ src/services/models/providers/anthropic.ts
  â†“ fetch('https://api.anthropic.com/v1/messages', ...)
  â†“ ì‘ë‹µ ëŒ€ê¸° (non-streaming)
  
[Coin Agent]
  â†“ ê²°ê³¼ ë°˜í™˜
  
[ì‚¬ìš©ì]
  â† ì‘ë‹µ ì¶œë ¥
```

### 4.3 í•µì‹¬ ì°¨ì´ì 

| ë‹¨ê³„ | OpenCode | SuperCoin |
|------|----------|-----------|
| **ëª¨ë¸ ë¡œë“œ** | Provider.getLanguage() (ì¶”ìƒí™”) | ì§ì ‘ í”„ë¡œë°”ì´ë” ì„ íƒ |
| **ì¸ì¦** | ìë™ (config + env + auth.json) | AuthHub ìˆ˜ë™ í˜¸ì¶œ |
| **ìŠ¤íŠ¸ë¦¬ë°** | streamText() (AI SDK) | fetch() ì§ì ‘ í˜¸ì¶œ |
| **ë„êµ¬ í˜¸ì¶œ** | ìë™ ê°ì§€ ë° ì‹¤í–‰ | ìˆ˜ë™ êµ¬í˜„ í•„ìš” |
| **ì—ëŸ¬ ì²˜ë¦¬** | AI SDK ë‚´ì¥ | ê° í”„ë¡œë°”ì´ë”ë³„ êµ¬í˜„ |

---

## 5. ê°œì„  ë°©í–¥: SuperCoin â†’ OpenCode êµ¬ì¡°

### 5.1 ëª©í‘œ

1. âœ… **Sisyphus â†’ Cent ë³€ê²½**: ì—ì´ì „íŠ¸ ì´ë¦„ë§Œ ë³€ê²½
2. âœ… **AI SDK í†µí•©**: Provider ì¶”ìƒí™” ë ˆì´ì–´ ì¶”ê°€
3. âœ… **localhost ì§€ì›**: Ollama, LM Studio ë“± ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©
4. âœ… **Zen ëª¨ë¸ ì œê±°**: ê¸°ë³¸ ëª¨ë¸ì„ localhostë¡œ ì„¤ì •
5. âœ… **ìŠ¤íŠ¸ë¦¬ë° ê°œì„ **: AI SDKì˜ streamText í™œìš©
6. âœ… **ì„¤ì • ê³„ì¸µí™”**: Project config ìš°ì„ ìˆœìœ„ ì¶”ê°€

### 5.2 ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜

```
supercoin/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ provider/                    # ğŸ†• AI SDK ê¸°ë°˜ í”„ë¡œë°”ì´ë” ì¶”ìƒí™”
â”‚   â”‚   â”œâ”€â”€ registry.ts             # í”„ë¡œë°”ì´ë” ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”‚   â”‚   â”œâ”€â”€ loaders/
â”‚   â”‚   â”‚   â”œâ”€â”€ anthropic.ts        # Anthropic ë¡œë”
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.ts           # OpenAI ë¡œë”
â”‚   â”‚   â”‚   â”œâ”€â”€ google.ts           # Google ë¡œë”
â”‚   â”‚   â”‚   â””â”€â”€ localhost.ts        # ğŸ†• Localhost ë¡œë” (Ollama, LM Studio)
â”‚   â”‚   â””â”€â”€ types.ts
â”‚   â”œâ”€â”€ session/                     # ğŸ†• ì„¸ì…˜ ê´€ë¦¬ ê°œì„ 
â”‚   â”‚   â”œâ”€â”€ manager.ts              # ì„¸ì…˜ ë§¤ë‹ˆì €
â”‚   â”‚   â”œâ”€â”€ llm.ts                  # ğŸ†• LLM ìŠ¤íŠ¸ë¦¬ë° (AI SDK)
â”‚   â”‚   â””â”€â”€ context.ts              # ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ coin.ts                 # âœï¸ Sisyphus â†’ Cent (ì´ë¦„ ë³€ê²½)
â”‚   â”‚   â”œâ”€â”€ explorer.ts
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ schema.ts               # âœï¸ Provider ì„¤ì • ì¶”ê°€
â”‚   â”‚   â””â”€â”€ loader.ts               # âœï¸ Project config ìš°ì„ ìˆœìœ„
â”‚   â””â”€â”€ ...
â””â”€â”€ opencode.json                    # ğŸ†• Project-level config
```

### 5.3 í•µì‹¬ ë³€ê²½ ì‚¬í•­

#### **A. Provider ì¶”ìƒí™” ì¶”ê°€**

```typescript
// src/provider/registry.ts
import { anthropic } from '@ai-sdk/anthropic'
import { openai } from '@ai-sdk/openai'
import { createOpenAI } from '@ai-sdk/openai-compatible'

export class ProviderRegistry {
  private providers = new Map<string, Provider>()
  
  register(name: string, config: ProviderConfig) {
    let sdk
    
    if (name === 'anthropic') {
      sdk = anthropic({
        apiKey: config.apiKey,
        baseURL: config.baseURL
      })
    } else if (name === 'localhost') {
      // Ollama, LM Studio ë“±
      sdk = createOpenAI({
        baseURL: config.baseURL || 'http://localhost:11434/v1',
        apiKey: 'dummy' // localhostëŠ” API í‚¤ ë¶ˆí•„ìš”
      })
    }
    
    this.providers.set(name, { sdk, config })
  }
  
  async getLanguageModel(provider: string, model: string) {
    const p = this.providers.get(provider)
    return p.sdk(model)
  }
}
```

#### **B. LLM ìŠ¤íŠ¸ë¦¬ë° í†µí•©**

```typescript
// src/session/llm.ts
import { streamText } from 'ai'

export async function stream(input: StreamInput) {
  const provider = await getProvider(input.model.provider)
  const languageModel = await provider.getLanguageModel(input.model.id)
  
  return streamText({
    model: languageModel,
    messages: input.messages,
    tools: input.tools,
    temperature: input.temperature,
    maxTokens: input.maxTokens,
    onFinish: (completion) => {
      saveToSession(completion)
    }
  })
}
```

#### **C. Coin ì—ì´ì „íŠ¸ (ì´ë¦„ ë³€ê²½)**

```typescript
// src/agents/coin.ts (ê¸°ì¡´ coin.tsì—ì„œ Sisyphus ë¡œì§ í†µí•©)
export class CoinAgent implements Agent {
  name = 'coin'
  
  async execute(prompt: string, context: AgentContext) {
    // Sisyphusì™€ ë™ì¼í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¡œì§
    const intent = await this.analyzeIntent(prompt)
    
    if (intent.type === 'explore') {
      return await this.delegateToExplore(prompt, context)
    } else if (intent.type === 'implement') {
      return await this.delegateToExecutor(prompt, context)
    }
    
    // ì§ì ‘ ì²˜ë¦¬
    return await this.handleDirectly(prompt, context)
  }
  
  private async handleDirectly(prompt: string, context: AgentContext) {
    const session = getSession(context.sessionId)
    
    // AI SDK ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©
    const result = await stream({
      model: { provider: 'localhost', id: 'llama3' },
      messages: session.messages.concat({ role: 'user', content: prompt }),
      tools: session.tools
    })
    
    return result
  }
}
```

---

## 6. Localhost ëª¨ë¸ í†µí•© ê°€ì´ë“œ

### 6.1 ì„¤ì • íŒŒì¼ êµ¬ì¡°

```jsonc
// opencode.json (í”„ë¡œì íŠ¸ ë£¨íŠ¸)
{
  "$schema": "https://opencode.ai/config.json",
  "model": "localhost/llama3:latest",           // ê¸°ë³¸ ëª¨ë¸ì„ localhostë¡œ ì„¤ì •
  "small_model": "localhost/qwen2.5-coder:7b",  // ê²½ëŸ‰ ì‘ì—…ìš© ëª¨ë¸
  
  "provider": {
    "localhost": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Local Ollama",
      "options": {
        "baseURL": "http://localhost:11434/v1"  // Ollama ê¸°ë³¸ í¬íŠ¸
      },
      "models": {
        "llama3:latest": {
          "name": "Llama 3 70B (local)",
          "capabilities": {
            "temperature": true,
            "reasoning": true,
            "toolcall": true,
            "input": { "text": true },
            "output": { "text": true }
          },
          "limit": {
            "context": 32768,
            "output": 4096
          }
        },
        "qwen2.5-coder:7b": {
          "name": "Qwen 2.5 Coder 7B (local)",
          "capabilities": {
            "temperature": true,
            "toolcall": true,
            "input": { "text": true },
            "output": { "text": true }
          },
          "limit": {
            "context": 8192,
            "output": 2048
          }
        }
      }
    }
  }
}
```

### 6.2 Ollama ì„¤ì • ë°©ë²•

```bash
# 1. Ollama ì„¤ì¹˜ (macOS)
brew install ollama

# 2. Ollama ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve

# 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama3:latest
ollama pull qwen2.5-coder:7b

# 4. API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
curl http://localhost:11434/v1/models
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "object": "list",
  "data": [
    {
      "id": "llama3:latest",
      "object": "model",
      "owned_by": "library"
    }
  ]
}
```

### 6.3 LM Studio ì„¤ì • ë°©ë²•

```jsonc
{
  "provider": {
    "lmstudio": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "LM Studio (local)",
      "options": {
        "baseURL": "http://127.0.0.1:1234/v1"  // LM Studio ê¸°ë³¸ í¬íŠ¸
      },
      "models": {
        "qwen3-coder": {
          "name": "Qwen3-Coder (LM Studio)",
          "limit": {
            "context": 32768,
            "output": 8192
          }
        }
      }
    }
  }
}
```

**LM Studio ì‹œì‘:**
1. LM Studio ì•± ì‹¤í–‰
2. "Local Server" íƒ­ ì„ íƒ
3. "Start Server" í´ë¦­
4. í¬íŠ¸ 1234ì—ì„œ OpenAI-compatible API ì œê³µ

### 6.4 llama.cpp ì„¤ì • ë°©ë²•

```bash
# 1. llama.cpp ë¹Œë“œ
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
make

# 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (GGUF í¬ë§·)
mkdir models
wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf -P models/

# 3. ì„œë²„ ì‹œì‘
./llama-server -m models/llama-2-7b-chat.Q4_K_M.gguf --port 8080 --host 127.0.0.1
```

**SuperCoin ì„¤ì •:**
```jsonc
{
  "provider": {
    "llama.cpp": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "llama-server (local)",
      "options": {
        "baseURL": "http://127.0.0.1:8080/v1"
      },
      "models": {
        "llama-2-7b-chat": {
          "name": "Llama 2 7B Chat (local)",
          "limit": {
            "context": 4096,
            "output": 2048
          }
        }
      }
    }
  }
}
```

---

## 7. êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: Provider ì¶”ìƒí™” ë ˆì´ì–´ ì¶”ê°€ (1ì£¼)

**ì‘ì—… í•­ëª©:**
- [ ] AI SDK ì˜ì¡´ì„± ì¶”ê°€ (`@ai-sdk/openai`, `@ai-sdk/anthropic`, `@ai-sdk/google`, `@ai-sdk/openai-compatible`, `ai`)
- [ ] `src/provider/registry.ts` êµ¬í˜„
- [ ] `src/provider/loaders/` ê° í”„ë¡œë°”ì´ë” ë¡œë” êµ¬í˜„
- [ ] `src/session/llm.ts` ìŠ¤íŠ¸ë¦¬ë° í†µí•©
- [ ] ê¸°ì¡´ ModelRouterë¥¼ Provider ì¶”ìƒí™” ì‚¬ìš©í•˜ë„ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜

**ê²€ì¦:**
```typescript
// í…ŒìŠ¤íŠ¸ ì½”ë“œ
const provider = new ProviderRegistry()
provider.register('anthropic', { apiKey: 'sk-...' })

const model = await provider.getLanguageModel('anthropic', 'claude-sonnet-4')
const result = await streamText({ model, messages: [...] })

console.log(result.text) // âœ… ì‘ë‹µ ì¶œë ¥
```

---

### Phase 2: Localhost ëª¨ë¸ í†µí•© (3ì¼)

**ì‘ì—… í•­ëª©:**
- [ ] `opencode.json` ìŠ¤í‚¤ë§ˆ ì •ì˜
- [ ] Localhost provider ë¡œë” êµ¬í˜„
- [ ] Ollama ì—°ë™ í…ŒìŠ¤íŠ¸
- [ ] LM Studio ì—°ë™ í…ŒìŠ¤íŠ¸
- [ ] ì„¤ì • íŒŒì¼ ë¡œë”ì—ì„œ localhost ìš°ì„ ìˆœìœ„ ì²˜ë¦¬

**ê²€ì¦:**
```bash
# Ollama ì‹œì‘
ollama serve
ollama pull llama3

# SuperCoin ì‹¤í–‰
supercoin chat "Hello world"
# â†’ localhost/llama3 ëª¨ë¸ë¡œ ì‘ë‹µ
```

---

### Phase 3: Coin ì—ì´ì „íŠ¸ í†µí•© (5ì¼)

**ì‘ì—… í•­ëª©:**
- [ ] ê¸°ì¡´ `coin.ts`ì— Sisyphus ë¡œì§ í†µí•©
- [ ] ì„œë¸Œ ì—ì´ì „íŠ¸ ìœ„ì„ ë¡œì§ êµ¬í˜„
- [ ] ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ê°œì„ 
- [ ] ë„êµ¬ í˜¸ì¶œ ìë™í™” (AI SDK tools)
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§

**ê²€ì¦:**
```typescript
const coin = new SuperCoin({ config })
await coin.initialize()

const result = await coin.runAgent('coin', 'Refactor this function to use async/await')
// â†’ Coinì´ ì½”ë“œ ë¶„ì„, ë¦¬íŒ©í† ë§ ì œì•ˆ, íŒŒì¼ ìˆ˜ì •ê¹Œì§€ ìë™ ìˆ˜í–‰
```

---

### Phase 4: ì„¤ì • ê³„ì¸µí™” (3ì¼)

**ì‘ì—… í•­ëª©:**
- [ ] Project config (`opencode.json`) ìš°ì„ ìˆœìœ„ ì¶”ê°€
- [ ] Global config (`~/.config/supercoin/config.json`) ì§€ì›
- [ ] Environment variable ì˜¤ë²„ë¼ì´ë“œ
- [ ] ì„¤ì • ë³‘í•© ë¡œì§ (remote â†’ global â†’ project â†’ env)

**ìš°ì„ ìˆœìœ„:**
```
Environment Variables (ìµœìš°ì„ )
  â†“
Project Config (opencode.json)
  â†“
Global Config (~/.config/supercoin/config.json)
  â†“
Default Values
```

---

### Phase 5: í…ŒìŠ¤íŠ¸ ë° ë¬¸ì„œí™” (5ì¼)

**ì‘ì—… í•­ëª©:**
- [ ] Unit tests (provider, session, llm)
- [ ] Integration tests (Ollama, LM Studio)
- [ ] E2E tests (ì „ì²´ ì›Œí¬í”Œë¡œìš°)
- [ ] README ì—…ë°ì´íŠ¸ (localhost ì„¤ì • ê°€ì´ë“œ)
- [ ] Migration guide (ê¸°ì¡´ SuperCoin â†’ ìƒˆ êµ¬ì¡°)

---

## 8. ì˜ˆìƒ íŒŒì¼ ë³€ê²½ ì‚¬í•­

### 8.1 ìƒˆë¡œ ì¶”ê°€ë  íŒŒì¼

```
src/
â”œâ”€â”€ provider/
â”‚   â”œâ”€â”€ registry.ts                 # ğŸ†• í”„ë¡œë°”ì´ë” ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”‚   â”œâ”€â”€ types.ts                    # ğŸ†• íƒ€ì… ì •ì˜
â”‚   â””â”€â”€ loaders/
â”‚       â”œâ”€â”€ anthropic.ts            # ğŸ†• Anthropic ë¡œë”
â”‚       â”œâ”€â”€ openai.ts               # ğŸ†• OpenAI ë¡œë”
â”‚       â”œâ”€â”€ google.ts               # ğŸ†• Google ë¡œë”
â”‚       â””â”€â”€ localhost.ts            # ğŸ†• Localhost ë¡œë”
â”œâ”€â”€ session/
â”‚   â””â”€â”€ llm.ts                      # ğŸ†• LLM ìŠ¤íŠ¸ë¦¬ë° (AI SDK)
â””â”€â”€ config/
    â””â”€â”€ project-loader.ts           # ğŸ†• Project config ë¡œë”
```

### 8.2 ìˆ˜ì •ë  íŒŒì¼

```
src/
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ coin.ts                     # âœï¸ Sisyphus ë¡œì§ í†µí•©
â”œâ”€â”€ services/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ router.ts               # âœï¸ Provider ì¶”ìƒí™” ì‚¬ìš©
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ schema.ts                   # âœï¸ Provider ì„¤ì • ì¶”ê°€
â”‚   â””â”€â”€ loader.ts                   # âœï¸ ê³„ì¸µí™”ëœ ì„¤ì • ë¡œë“œ
â””â”€â”€ supercoin.ts                    # âœï¸ Provider ì´ˆê¸°í™”
```

### 8.3 ì œê±°ë  íŒŒì¼

```
src/services/models/providers/
â”œâ”€â”€ anthropic.ts                    # âŒ ì œê±° (Providerë¡œ ëŒ€ì²´)
â”œâ”€â”€ openai.ts                       # âŒ ì œê±°
â””â”€â”€ google.ts                       # âŒ ì œê±°
```

---

## 9. ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‚¬ìš©ì ê´€ì  (Breaking Changes)

- [ ] **ì„¤ì • íŒŒì¼ ë³€ê²½**: `config.toml` â†’ `opencode.json`
- [ ] **ëª¨ë¸ ID í˜•ì‹**: `anthropic/claude-sonnet-4` â†’ `localhost/llama3`
- [ ] **CLI ëª…ë ¹ì–´**: ê¸°ì¡´ê³¼ ë™ì¼ (í˜¸í™˜ì„± ìœ ì§€)
- [ ] **ì¸ì¦**: ê¸°ì¡´ í† í° ìŠ¤í† ì–´ ìœ ì§€ (ë³€ê²½ ì—†ìŒ)

### ê°œë°œì ê´€ì 

- [ ] **ì˜ì¡´ì„± ì¶”ê°€**: AI SDK íŒ¨í‚¤ì§€ ì„¤ì¹˜
- [ ] **API ë³€ê²½**: `ModelRouter.route()` â†’ `Provider.getLanguageModel()`
- [ ] **ìŠ¤íŠ¸ë¦¬ë°**: ì§ì ‘ fetch â†’ `streamText()`
- [ ] **ì—ëŸ¬ ì²˜ë¦¬**: AI SDK ì—ëŸ¬ íƒ€ì… ì‚¬ìš©

---

## 10. FAQ

### Q1: ì™œ OpenCode êµ¬ì¡°ë¥¼ ë”°ë¼ì•¼ í•˜ë‚˜ìš”?

**A:** OpenCodeëŠ” ì´ë¯¸ 75+ í”„ë¡œë°”ì´ë”ë¥¼ ì§€ì›í•˜ëŠ” ê²€ì¦ëœ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤. AI SDKë¥¼ í™œìš©í•˜ë©´:
- localhost ëª¨ë¸ì„ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
- í”„ë¡œë°”ì´ë”ë³„ API ì°¨ì´ë¥¼ ì‹ ê²½ ì“¸ í•„ìš” ì—†ìŒ
- ìŠ¤íŠ¸ë¦¬ë°, ë„êµ¬ í˜¸ì¶œ, ì—ëŸ¬ ì²˜ë¦¬ê°€ í†µí•©ë¨
- ìƒˆë¡œìš´ í”„ë¡œë°”ì´ë” ì¶”ê°€ê°€ ë§¤ìš° ì‰¬ì›€

### Q2: Sisyphus â†’ Centìœ¼ë¡œ ì´ë¦„ë§Œ ë°”ê¾¸ë©´ ë˜ë‚˜ìš”?

**A:** ê±°ì˜ ë§ìŠµë‹ˆë‹¤. í•µì‹¬ ë¡œì§ì€ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ë˜, SuperCoinì˜ ê¸°ì¡´ ì•„í‚¤í…ì²˜ì™€ ì˜ í†µí•©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. Coinì€:
- Sisyphusì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¡œì§ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- SuperCoinì˜ Provider ì¶”ìƒí™”ì™€ í†µí•©
- localhost ëª¨ë¸ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©

### Q3: ê¸°ì¡´ ì‚¬ìš©ìì˜ ì„¤ì •ì€ ì–´ë–»ê²Œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ë‚˜ìš”?

**A:** ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì œê³µ:
```bash
supercoin migrate-config
# â†’ config.toml â†’ opencode.json ìë™ ë³€í™˜
# â†’ ê¸°ì¡´ API í‚¤ ìœ ì§€
# â†’ localhost ëª¨ë¸ ì¶”ì²œ
```

### Q4: Zen ëª¨ë¸ ì—†ì´ë„ ê´œì°®ë‚˜ìš”?

**A:** ë„¤, ë¬¸ì œì—†ìŠµë‹ˆë‹¤. Zenì€ í¸ì˜ì„±ì„ ìœ„í•œ ê²ƒì´ê³ , localhost ëª¨ë¸ë¡œë„ ì¶©ë¶„íˆ ê°•ë ¥í•©ë‹ˆë‹¤:
- Llama 3 70B: GPT-4ê¸‰ ì„±ëŠ¥
- Qwen 2.5 Coder: ì½”ë”© íŠ¹í™”
- ë¹„ìš© ë¬´ë£Œ (ë¡œì»¬ ì‹¤í–‰)
- í”„ë¼ì´ë²„ì‹œ ë³´ì¥

---

## 11. ê²°ë¡ 

OpenCodeì˜ ì•„í‚¤í…ì²˜ë¥¼ SuperCoinì— í†µí•©í•˜ë©´:

âœ… **í™•ì¥ì„±**: 75+ í”„ë¡œë°”ì´ë” ì¦‰ì‹œ ì§€ì›  
âœ… **localhost ìš°ì„ **: Ollama, LM Studioë¡œ ë¬´ë£Œ ì‚¬ìš©  
âœ… **ìŠ¤íŠ¸ë¦¬ë° ê°œì„ **: AI SDKì˜ ì•ˆì •ì ì¸ ìŠ¤íŠ¸ë¦¬ë°  
âœ… **Sisyphus â†’ Cent**: ê²€ì¦ëœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¡œì§  
âœ… **í˜¸í™˜ì„±**: ê¸°ì¡´ ì¸ì¦, ì„¤ì • ì‹œìŠ¤í…œ ìœ ì§€

**ë‹¤ìŒ ë‹¨ê³„**: Phase 1ë¶€í„° ì‹œì‘í•˜ì—¬ 5ì£¼ ë‚´ ì™„ë£Œ ëª©í‘œ
